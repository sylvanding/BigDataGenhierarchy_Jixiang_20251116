%%
% BIThesis 实验报告模板 The BIThesis Template for Experiment Report
% This file has no copyright assigned and is placed in the Public Domain.
% Compile with: xelatex -> biber -> xelatex -> xelatex
%%

% 请勿删除下面两行注释，以免影响编译。
% !TeX program = xelatex
% !BIB program = biber

\documentclass[]{bitreport}

% 将你的相关信息替换如下示例
\BITSetup{
  cover = {
    % 在封面中载入有「北京理工大学销毁」的图片，如无必要请勿改动。
    imagePath = { assets/logo_bit.png },
    %% 使用以下参数来自定义封面日期
    date = {2025年11月16日}
  },
  info = {
    % 想要删除某项封面信息，直接删除该项即可。
    % 想要让某项封面信息留空（但是保留下划线），请传入空白符组成的字符串，如"{~}"。
    % 如需要换行，则用 “\\” 符号分割。
    title = {大数据泛构实验报告2},
    school = {珠海校区},
    major = {计算机科学与技术},
    studentId = {3120256739},
    author = {丁纪翔},
    supervisor = {毛睿},
  }
}

%% 参考文献
\usepackage[style=gb7714-2015,backend=biber]{biblatex}
% Required by `figure`.
\usepackage{float,graphicx}
% Code listings
\usepackage{listings}
\usepackage{xcolor}
% Math symbols and environments
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pifont}

% 超链接支持（让目录可点击跳转）
\usepackage[
    colorlinks=true,      % 使用彩色链接
    linkcolor=blue,       % 内部链接颜色（目录、交叉引用等）
    citecolor=blue,       % 引用链接颜色
    urlcolor=blue,        % URL链接颜色
    bookmarksnumbered,    % PDF书签显示章节编号
    pdfstartview=FitH,    % PDF打开时适应页面宽度
]{hyperref}

% Java代码样式配置
\lstdefinestyle{javastyle}{
    language=Java,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=8pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)},
    xleftmargin=2em,
    xrightmargin=2em,
    aboveskip=1em,
    belowskip=1em
}

\lstset{style=javastyle}

\addbibresource{misc/refs.bib}

% 设置PDF文档属性
\hypersetup{
    pdftitle={大数据泛构实验报告2},
    pdfauthor={丁纪翔},
    pdfsubject={大数据实验报告},
    pdfkeywords={大数据, 度量空间, 相似性查询, 索引}
}

\begin{document}

% 制作封面
\MakeCover

% 生成目录
\tableofcontents
\clearpage

\section{引言}

\subsection{研究背景与意义}

在大数据时代，数据的多样性(Variety)是大数据三大特征之一。面对图片、文本、音频、生物序列等多种数据类型，传统的专用数据处理系统需要为每种数据类型量身定做，开发和维护成本巨大。度量空间(Metric Space)作为一种统一的数据抽象，为构建通用的数据管理与分析系统提供了理论基础。

度量空间的核心思想是：只要数据之间可以定义满足度量空间性质(非负性、对称性、三角不等性)的距离函数，就可以使用相同的算法处理不同类型的数据。这种"求同存异"的思想，使得我们可以用统一的相似性查询和索引技术处理多种数据类型，大大降低了系统的开发和维护成本。

相似性查询是度量空间数据管理的核心功能，广泛应用于图像检索、推荐系统、异常检测等场景。然而，随着数据规模的增长，线性扫描的查询方式效率低下。索引技术通过预计算和剪枝策略，可以显著减少距离计算次数，提升查询性能。Pivot Table(支撑点表)是一种经典的度量空间索引结构，利用三角不等式进行剪枝，在保证查询准确性的同时大幅提升效率。

\subsection{任务回顾与目标}

\subsubsection{Assignment 1 工作简述}

在Assignment 1中，我们构建了度量空间数据管理的基础框架：

\begin{enumerate}
  \item \textbf{核心抽象类设计}：设计了\texttt{MetricSpaceData}抽象父类和\texttt{MetricFunction}接口，为不同数据类型提供统一的抽象层。

  \item \textbf{向量数据类型}：实现了\texttt{VectorData}类，支持任意维度的向量数据，以及基于闵可夫斯基距离(Minkowski Distance)的距离计算，包括$L_1$(曼哈顿距离)、$L_2$(欧几里得距离)和$L_\infty$(切比雪夫距离)。

  \item \textbf{蛋白质序列类型}：实现了\texttt{ProteinData}类，支持蛋白质序列的6-mers片段表示，以及基于mPAM250a替代矩阵的全局序列比对距离(Alignment Distance)。

  \item \textbf{数据读取功能}：实现了向量数据和蛋白质序列数据的读取器，支持UMAD数据集格式。
\end{enumerate}

\subsubsection{Assignment 2 核心目标}

在Assignment 1的基础上，Assignment 2聚焦于度量空间的相似性查询与索引：

\begin{enumerate}
  \item \textbf{线性扫描查询}：实现三种基本的相似性查询算法——范围查询(Range Query)、k近邻查询(kNN Query)和多样化k近邻查询(dkNN Query)。

  \item \textbf{Pivot Table索引}：实现基于支撑点表的索引结构，利用三角不等式进行剪枝优化，减少距离计算次数。

  \item \textbf{功能正确性验证}：设计易于验证的测试用例，确保查询和索引功能的正确性。

  \item \textbf{性能分析与探索}：深入分析支撑点数量和选择策略对查询性能的影响，揭示Pivot Table索引的加速效果。
\end{enumerate}

\subsection{实验环境}

本实验的软硬件环境如下：

\begin{itemize}
  \item \textbf{操作系统}：Windows 11 (10.0.26100)
  \item \textbf{开发语言}：Java 18.0.2.1
  \item \textbf{构建工具}：Apache Maven 3.9.11
  \item \textbf{开发环境}：VS Code
  \item \textbf{测试框架}：JUnit 4.13.2
  \item \textbf{数据集}：UMAD (Universal Management and Analysis of Data)
  \begin{itemize}
    \item Uniform 20-d vector：20维均匀分布向量，100万个数据点
    \item 测试规模：1000, 5000, 10000个数据点
  \end{itemize}
  \item \textbf{硬件配置}：Intel Core处理器，8GB内存
\end{itemize}

\subsection{报告结构}

本报告共分为6章：

\begin{itemize}
  \item \textbf{第1章 引言}：介绍研究背景、任务目标和实验环境。
  \item \textbf{第2章 系统设计}：详细阐述线性扫描查询和Pivot Table索引的设计原理。
  \item \textbf{第3章 核心功能实现}：展示关键代码实现和技术细节。
  \item \textbf{第4章 功能正确性验证}：通过测试用例验证系统功能的正确性。
  \item \textbf{第5章 性能分析与探索}：分析支撑点数量、选择策略对性能的影响。
  \item \textbf{第6章 总结与展望}：总结工作成果，展望未来改进方向。
\end{itemize}


\section{相似性查询与索引系统设计}

\subsection{系统架构扩展}

\subsubsection{在原有架构中集成查询与索引模块}

在Assignment 1构建的基础架构之上，我们扩展了两个核心模块：

\begin{enumerate}
  \item \textbf{查询模块(query包)}：实现三种线性扫描查询算法
  \begin{itemize}
    \item \texttt{LinearScanRangeQuery}：范围查询
    \item \texttt{LinearScanKNNQuery}：k近邻查询
    \item \texttt{LinearScanDKNNQuery}：多样化k近邻查询
  \end{itemize}

  \item \textbf{索引模块(index包)}：实现Pivot Table索引结构
  \begin{itemize}
    \item \texttt{PivotTable}：索引数据结构
    \item \texttt{PivotSelector}：支撑点选择器
    \item \texttt{PivotTableRangeQuery}：基于索引的范围查询
    \item \texttt{PivotTableKNNQuery}：基于索引的kNN查询
  \end{itemize}
\end{enumerate}

这两个模块与Assignment 1的核心抽象类(\texttt{MetricSpaceData}、\texttt{MetricFunction})和数据类型实现(\texttt{VectorData}、\texttt{ProteinData})无缝集成，体现了度量空间通用数据处理的设计思想。

\subsubsection{更新后的系统模块划分}

完整的系统架构分为五层：

\begin{enumerate}
  \item \textbf{核心抽象层(core包)}：定义度量空间数据和距离函数的抽象接口
  \item \textbf{数据类型层(datatype包)}：实现具体的数据类型和距离函数
  \item \textbf{数据IO层(io包)}：负责数据集的读取和解析
  \item \textbf{查询层(query包)}：实现线性扫描查询算法
  \item \textbf{索引层(index包)}：实现Pivot Table索引和基于索引的查询
\end{enumerate}

该架构遵循"依赖倒置原则"，高层模块(查询、索引)依赖于抽象(核心接口)，而非具体实现，保证了系统的可扩展性和通用性。

\subsection{线性扫描查询算法设计}

线性扫描(Linear Scan)是最直观的查询方法，通过遍历数据集中的每个对象，逐一计算与查询对象的距离，筛选出满足条件的结果。虽然效率较低，但线性扫描保证了结果的准确性，常用作验证索引查询正确性的基准。

\subsubsection{范围查询(Range Query)算法原理}

\textbf{定义}：给定查询对象$q$和查询半径$r$，范围查询返回数据集$S$中所有与$q$距离不超过$r$的对象：

\[
RQ(q, r) = \{ s \in S \mid d(q, s) \leq r \}
\]

其中$d$是度量空间中的距离函数。

\textbf{算法流程}：

\begin{enumerate}
  \item 初始化结果集$R$为空集
  \item 遍历数据集$S$中的每个对象$s$
  \item 计算查询对象$q$与$s$的距离$d(q, s)$
  \item 如果$d(q, s) \leq r$，将$s$加入结果集$R$
  \item 返回结果集$R$
\end{enumerate}

\textbf{复杂度分析}：
\begin{itemize}
  \item 时间复杂度：$O(n)$，其中$n$是数据集大小
  \item 距离计算次数：$n$次
  \item 空间复杂度：$O(k)$，其中$k$是结果集大小
\end{itemize}

\textbf{示例}：假设数据集包含5个二维向量，使用$L_2$距离，查询对象为原点$(0,0)$，查询半径$r=1.5$：

\begin{table}[H]
  \centering
  \begin{tabular}{ccc}
    \hline
    数据对象 & 与原点距离 & 是否在结果中 \\
    \hline
    $(0, 0)$ & 0 & \ding{51} \\
    $(1, 0)$ & 1 & \ding{51} \\
    $(0, 1)$ & 1 & \ding{51} \\
    $(3, 4)$ & 5 & \ding{55} \\
    $(5, 5)$ & 7.07 & \ding{55} \\
    \hline
  \end{tabular}
  \caption{范围查询示例}
\end{table}

\subsubsection{k近邻查询(kNN)算法原理}

\textbf{定义}：给定查询对象$q$和整数$k$，kNN查询返回数据集$S$中距离$q$最近的$k$个对象：

\[
kNN(q, k) = \{ k \text{个最近邻} \mid \forall s \in kNN(q,k), \forall s' \notin kNN(q,k): d(q,s) \leq d(q,s') \}
\]

\textbf{算法流程}：

\begin{enumerate}
  \item 创建最大堆$H$(优先队列)，用于维护当前k个最近邻
  \item 遍历数据集$S$中的每个对象$s$
  \item 计算查询对象$q$与$s$的距离$dist = d(q, s)$
  \item 如果$|H| < k$，直接将$(s, dist)$插入堆$H$
  \item 否则，如果$dist < H.top().distance$，移除堆顶，插入$(s, dist)$
  \item 将堆$H$转换为按距离升序排列的列表并返回
\end{enumerate}

\textbf{复杂度分析}：
\begin{itemize}
  \item 时间复杂度：$O(n \log k)$
  \item 距离计算次数：$n$次
  \item 空间复杂度：$O(k)$
\end{itemize}

\textbf{关键数据结构}：使用最大堆维护当前k个最近邻，堆顶元素是当前k个邻居中距离最大的。这样每次只需与堆顶比较，如果新对象距离更小，则替换堆顶，保持堆中始终是距离最小的k个对象。

\subsubsection{多样化k近邻查询(dkNN)算法原理}

\textbf{动机}：传统kNN可能返回非常相似的对象(如都来自同一聚类)，缺乏多样性。例如，查询"苹果"的图片，传统kNN可能返回10张红苹果，而dkNN会返回红苹果、青苹果、苹果树等多样化的结果。

\textbf{定义}：多样化kNN在保证相关性(与查询对象距离小)的同时，最大化结果集的多样性(结果之间距离大)。定义得分函数：

\[
score(c) = (1-\lambda) \cdot (-d(q,c)) + \lambda \cdot \min_{r \in R} d(c, r)
\]

其中：
\begin{itemize}
  \item $\lambda \in [0,1]$是多样性权重
  \item $d(q,c)$是候选对象$c$与查询对象$q$的距离(相关性项)
  \item $\min_{r \in R} d(c,r)$是$c$与当前结果集$R$中最近对象的距离(多样性项)
\end{itemize}

\textbf{算法流程}(贪心策略)：

\begin{enumerate}
  \item 执行kNN查询，获取$k \times \alpha$个候选($\alpha > 1$，如$\alpha=2$)
  \item 初始化结果集$R$为空
  \item 将距离查询对象最近的候选加入$R$
  \item 当$|R| < k$且还有候选时：
  \begin{itemize}
    \item 对每个候选$c$，计算得分$score(c)$
    \item 选择得分最高的候选加入$R$
  \end{itemize}
  \item 返回结果集$R$
\end{enumerate}

\textbf{参数影响}：
\begin{itemize}
  \item $\lambda = 0$：退化为传统kNN，只考虑相关性
  \item $\lambda = 1$：完全追求多样性，可能牺牲相关性
  \item $\lambda = 0.5$：平衡相关性和多样性
\end{itemize}

\subsection{Pivot Table索引设计}

Pivot Table是一种基于距离预计算和三角不等式剪枝的度量空间索引结构，其核心思想是通过少量的距离计算和大量的数值比较来加速查询。

\subsubsection{核心思想：基于三角不等式的剪枝}

\textbf{三角不等式}：度量空间中的距离函数满足：

\[
d(x, z) \leq d(x, y) + d(y, z)
\]

等价形式：

\[
d(x, z) \geq |d(x, y) - d(y, z)|
\]

\textbf{剪枝原理}：利用三角不等式，可以在不计算实际距离的情况下判断某些数据对象是否满足查询条件。

\textbf{排除规则}(Exclusion Rule)：对于支撑点$p$、查询对象$q$、数据对象$s$和查询半径$r$：

\[
\text{如果} \quad |d(p,q) - d(p,s)| > r \quad \Rightarrow \quad d(q,s) > r
\]

\textbf{证明}：由三角不等式$d(q,s) \geq |d(p,q) - d(p,s)|$，若$|d(p,q) - d(p,s)| > r$，则必有$d(q,s) > r$，因此$s$不在查询结果中，可以直接排除。

\textbf{包含规则}(Inclusion Rule)：

\[
\text{如果} \quad d(p,q) + d(p,s) \leq r \quad \Rightarrow \quad d(q,s) \leq r
\]

\textbf{证明}：由三角不等式$d(q,s) \leq d(q,p) + d(p,s) = d(p,q) + d(p,s)$，若$d(p,q) + d(p,s) \leq r$，则必有$d(q,s) \leq r$，因此$s$一定在查询结果中，可以直接包含。

\textbf{几何直观}：以支撑点$p$为中心：
\begin{itemize}
  \item 若$s$在以$p$为中心、半径为$d(p,s)$的圆上
  \item 若$q$在以$p$为中心、半径为$d(p,q)$的圆上
  \item 当$|d(p,q) - d(p,s)|$很大时，$s$必然在以$q$为中心、半径为$r$的查询圆之外
\end{itemize}

\subsubsection{数据结构设计与构建流程}

\textbf{数据结构}：

Pivot Table包含三个核心组件：

\begin{lstlisting}[language=Java,caption=Pivot Table数据结构]
public class PivotTable {
    private List<MetricSpaceData> pivots;     // k个支撑点
    private List<MetricSpaceData> data;       // n个数据对象
    private double[][] distanceTable;         // n×k距离表
    private MetricFunction metric;            // 距离函数

    // distanceTable[i][j] = d(data[i], pivots[j])
}
\end{lstlisting}

\textbf{构建流程}：

\begin{enumerate}
  \item \textbf{支撑点选择}：根据选择策略(RANDOM/FFT/CENTER/BORDER)从数据集中选择$k$个支撑点
  \item \textbf{距离预计算}：计算每个数据对象到每个支撑点的距离，填充距离表
  \item \textbf{存储}：保存支撑点列表、数据列表和距离表
\end{enumerate}

\textbf{构建复杂度}：
\begin{itemize}
  \item 距离计算次数：$n \times k$次
  \item 存储空间：$O(n \times k)$
  \item 对于FFT选择策略，支撑点选择需要额外$O(n \times k^2)$次距离计算
\end{itemize}

\subsubsection{基于Pivot Table的范围查询流程}

\textbf{查询流程}：

\begin{enumerate}
  \item \textbf{预计算}：计算查询对象$q$到所有支撑点的距离$dpq[j] = d(q, pivots[j])$，共$k$次距离计算

  \item \textbf{剪枝判断}：对每个数据对象$data[i]$：
  \begin{itemize}
    \item 遍历每个支撑点$j$，获取$dps = distanceTable[i][j]$
    \item \textbf{包含规则}：若$dpq[j] + dps \leq r$，直接将$data[i]$加入结果，跳过该对象
    \item \textbf{排除规则}：若$|dpq[j] - dps| > r$，标记该对象为剪枝，跳过该对象
  \end{itemize}

  \item \textbf{实际距离计算}：对无法通过剪枝判断的对象，计算$d(q, data[i])$，若$\leq r$则加入结果

  \item \textbf{返回结果集}
\end{enumerate}

\textbf{性能优势}：
\begin{itemize}
  \item 理想情况：若所有对象都被剪枝，距离计算仅$k$次
  \item 实际情况：距离计算$k + \alpha \times n$次，其中$\alpha \in [0,1]$是未被剪枝的比例
  \item 剪枝率：$(1 - \alpha) \times 100\%$，通常可达70\%-99\%
\end{itemize}

\subsubsection{基于Pivot Table的kNN查询流程}

kNN查询的关键改进是\textbf{动态查询半径}策略：

\textbf{查询流程}：

\begin{enumerate}
  \item 初始化最大堆$H$和当前查询半径$r_{current} = +\infty$

  \item 预计算查询对象$q$到所有支撑点的距离$dpq[j]$

  \item 对每个数据对象$data[i]$：
  \begin{itemize}
    \item 使用$r_{current}$进行排除规则剪枝：若$|dpq[j] - dps| > r_{current}$，跳过
    \item 否则计算实际距离$dist = d(q, data[i])$
    \item 更新堆$H$：
    \begin{itemize}
      \item 若$|H| < k$，插入$(data[i], dist)$，当$|H| = k$时更新$r_{current} = H.top().distance$
      \item 若$dist < r_{current}$，移除堆顶，插入$(data[i], dist)$，更新$r_{current}$
    \end{itemize}
  \end{itemize}

  \item 返回堆$H$中的k个最近邻
\end{enumerate}

\textbf{动态半径的优势}：
\begin{itemize}
  \item 随着查询进行，发现更近的邻居，$r_{current}$不断缩小
  \item $r_{current}$越小，排除规则的剪枝效果越好
  \item 后期遍历的对象被剪枝的概率更高
\end{itemize}

\textbf{与范围查询的区别}：
\begin{itemize}
  \item 范围查询：半径$r$固定
  \item kNN查询：半径$r_{current}$动态变化，从$+\infty$逐渐缩小到第k个最近邻的距离
\end{itemize}


\section{核心功能实现}

本章展示系统的核心代码实现，重点说明关键算法和技术细节。由于完整代码较长，此处展示关键片段。

\subsection{线性扫描查询实现}

\subsubsection{范围查询(Range Query)核心代码}

范围查询的实现遍历数据集，计算每个对象与查询对象的距离，筛选出距离不超过半径的对象。

\begin{lstlisting}[caption=线性扫描范围查询实现]
public class LinearScanRangeQuery {
    public static List<MetricSpaceData> execute(
            List<? extends MetricSpaceData> dataset,
            RangeQuery query,
            MetricFunction metric) {

        List<MetricSpaceData> results = new ArrayList<>();
        MetricSpaceData queryObject = query.getQueryObject();
        double radius = query.getRadius();

        // 遍历数据集中的每个对象
        for (MetricSpaceData data : dataset) {
            // 计算距离
            double distance = metric.getDistance(queryObject, data);

            // 判断是否在查询半径内
            if (distance <= radius) {
                results.add(data);
            }
        }

        return results;
    }
}
\end{lstlisting}

\textbf{关键点}：
\begin{itemize}
  \item 使用泛型\texttt{List<? extends MetricSpaceData>}支持所有度量空间数据类型
  \item 通过\texttt{MetricFunction}接口调用距离函数，实现算法的通用性
  \item 时间复杂度$O(n)$，距离计算次数为$n$
\end{itemize}

\subsubsection{k近邻查询(kNN)核心代码}

kNN查询使用优先队列(最大堆)维护当前k个最近邻。

\begin{lstlisting}[caption=线性扫描kNN查询实现]
public class LinearScanKNNQuery {
    public static List<KNNResult> execute(
            List<? extends MetricSpaceData> dataset,
            KNNQuery query,
            MetricFunction metric) {

        MetricSpaceData queryObject = query.getQueryObject();
        int k = query.getK();

        // 最大堆:堆顶是当前k个邻居中距离最大的
        PriorityQueue<KNNResult> maxHeap = new PriorityQueue<>(
            (a, b) -> Double.compare(b.getDistance(), a.getDistance())
        );

        // 遍历数据集
        for (MetricSpaceData data : dataset) {
            double distance = metric.getDistance(queryObject, data);

            if (maxHeap.size() < k) {
                // 堆未满,直接加入
                maxHeap.offer(new KNNResult(data, distance));
            } else if (distance < maxHeap.peek().getDistance()) {
                // 找到更近的邻居,替换堆顶
                maxHeap.poll();
                maxHeap.offer(new KNNResult(data, distance));
            }
        }

        // 转换为升序列表
        List<KNNResult> results = new ArrayList<>(maxHeap);
        Collections.sort(results,
            (a, b) -> Double.compare(a.getDistance(), b.getDistance()));

        return results;
    }
}
\end{lstlisting}

\textbf{关键点}：
\begin{itemize}
  \item 使用最大堆保持堆中是距离最小的k个对象，堆顶是第k小的距离
  \item 每次只需与堆顶比较，避免对所有结果排序，时间复杂度$O(n \log k)$
  \item \texttt{KNNResult}封装了数据对象和距离，方便结果处理
\end{itemize}

\subsection{Pivot Table索引实现}

\subsubsection{Pivot Table构建核心代码}

\begin{lstlisting}[caption=Pivot Table构建实现]
public class PivotTable {
    private List<MetricSpaceData> pivots;
    private List<MetricSpaceData> data;
    private double[][] distanceTable;
    private MetricFunction metric;

    public PivotTable(List<? extends MetricSpaceData> dataset,
                     int pivotCount,
                     MetricFunction metric,
                     PivotSelectionMethod method) {
        this.data = new ArrayList<>(dataset);
        this.metric = metric;

        // 选择支撑点
        this.pivots = PivotSelector.selectPivots(
            dataset, pivotCount, metric, method);

        // 构建距离表
        buildDistanceTable();
    }

    private void buildDistanceTable() {
        int n = data.size();
        int k = pivots.size();
        distanceTable = new double[n][k];

        // 计算每个数据对象到每个支撑点的距离
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < k; j++) {
                distanceTable[i][j] =
                    metric.getDistance(data.get(i), pivots.get(j));
            }
        }
    }
}
\end{lstlisting}

\subsubsection{支撑点选择(FFT策略)实现}

\begin{lstlisting}[caption=FFT支撑点选择算法]
private static List<MetricSpaceData> farthestFirstTraversal(
        List<? extends MetricSpaceData> dataset,
        int pivotCount,
        MetricFunction metric) {

    List<MetricSpaceData> pivots = new ArrayList<>();

    // 第一个支撑点:随机选择
    pivots.add(dataset.get(new Random().nextInt(dataset.size())));

    // 选择剩余k-1个支撑点
    for (int i = 1; i < pivotCount; i++) {
        MetricSpaceData farthest = null;
        double maxMinDist = -1;

        // 找到距离已选支撑点最远的点
        for (MetricSpaceData candidate : dataset) {
            if (pivots.contains(candidate)) continue;

            // 计算到已选支撑点的最小距离
            double minDist = Double.MAX_VALUE;
            for (MetricSpaceData pivot : pivots) {
                double dist = metric.getDistance(candidate, pivot);
                minDist = Math.min(minDist, dist);
            }

            // 更新最远点
            if (minDist > maxMinDist) {
                maxMinDist = minDist;
                farthest = candidate;
            }
        }

        pivots.add(farthest);
    }

    return pivots;
}
\end{lstlisting}

\textbf{关键点}：
\begin{itemize}
  \item FFT策略每次选择距离已选支撑点最远的点，保证支撑点分布均匀
  \item 构建复杂度：距离表$O(nk)$，FFT选择$O(nk^2)$
  \item 距离表使用二维数组存储，空间$O(nk)$
\end{itemize}

\subsubsection{基于Pivot Table的范围查询实现}

\begin{lstlisting}[caption=Pivot Table范围查询]
public class PivotTableRangeQuery {
    public static List<MetricSpaceData> execute(
            PivotTable pivotTable,
            RangeQuery query) {

        List<MetricSpaceData> results = new ArrayList<>();
        MetricSpaceData queryObject = query.getQueryObject();
        double radius = query.getRadius();

        List<MetricSpaceData> pivots = pivotTable.getPivots();
        List<MetricSpaceData> data = pivotTable.getData();
        double[][] distanceTable = pivotTable.getDistanceTable();
        MetricFunction metric = pivotTable.getMetric();

        // 预计算:查询对象到所有支撑点的距离
        double[] dpq = new double[pivots.size()];
        for (int j = 0; j < pivots.size(); j++) {
            dpq[j] = metric.getDistance(queryObject, pivots.get(j));
        }

        // 对每个数据对象进行剪枝判断
        for (int i = 0; i < data.size(); i++) {
            boolean pruned = false;
            boolean included = false;

            // 遍历所有支撑点
            for (int j = 0; j < pivots.size(); j++) {
                double dps = distanceTable[i][j];

                // 包含规则
                if (dpq[j] + dps <= radius) {
                    results.add(data.get(i));
                    included = true;
                    break;
                }

                // 排除规则
                if (Math.abs(dpq[j] - dps) > radius) {
                    pruned = true;
                    break;
                }
            }

            // 无法剪枝,计算实际距离
            if (!pruned && !included) {
                double actualDist = metric.getDistance(
                    queryObject, data.get(i));
                if (actualDist <= radius) {
                    results.add(data.get(i));
                }
            }
        }

        return results;
    }
}
\end{lstlisting}


\section{功能正确性验证}

本章通过设计易于验证的测试用例，验证线性扫描查询和Pivot Table索引的功能正确性。

\subsection{测试环境与数据集}

\textbf{测试环境}：
\begin{itemize}
  \item JUnit 4.13.2测试框架
  \item 数据集：Uniform 20-d vector
  \item 测试规模：10个数据点(小规模，便于人工验证)
  \item 距离函数：$L_2$欧几里得距离
\end{itemize}

\textbf{测试策略}：
\begin{enumerate}
  \item 使用小规模数据集，输出详细的计算过程
  \item 对比线性扫描和Pivot Table索引的查询结果
  \item 验证结果集大小、对象和距离的一致性
  \item 验证度量空间三大性质(非负性、对称性、三角不等性)
\end{enumerate}

\subsection{线性扫描查询正确性验证}

\subsubsection{范围查询(Range Query)测试}

\textbf{测试用例}：数据集包含10个20维向量，查询对象为第一个向量，查询半径分别为0.05、0.10、0.15、0.20。

\textbf{测试输出}(部分)：

\begin{verbatim}
==================================================
线性扫描范围查询测试
==================================================

【测试配置】
  数据集大小: 10 个向量
  查询对象: Vector[0]
  距离函数: L2 (欧几里得距离)

【查询半径 r = 0.05】
  计算距离过程:
    d(q, data[0]) = 0.0000    <=  0.05  [包含]
    d(q, data[1]) = 0.8654    >   0.05  [排除]
    d(q, data[2]) = 0.7923    >   0.05  [排除]
    ...
  结果数量: 1
  距离计算次数: 10

【查询半径 r = 0.10】
  结果数量: 1
  距离计算次数: 10
\end{verbatim}

\textbf{验证结论}：
\begin{itemize}
  \item \ding{51} 所有测试用例通过
  \item \ding{51} 结果集大小随半径增大而增大或不变
  \item \ding{51} 距离计算次数恒为数据集大小$n=10$
  \item \ding{51} 查询对象自身始终在结果集中(距离为0)
\end{itemize}

\subsubsection{k近邻查询(kNN)测试}

\textbf{测试用例}：数据集10个向量，$k$分别为5、10、20、50。

\textbf{验证结论}：
\begin{itemize}
  \item \ding{51} 结果按距离升序排列
  \item \ding{51} $k \leq n$时返回$k$个结果，$k > n$时返回全部$n$个结果
  \item \ding{51} 第一个结果是查询对象自身(距离为0)
  \item \ding{51} 相邻结果的距离单调不减
\end{itemize}

\subsubsection{多样化k近邻查询(dkNN)测试}

\textbf{测试用例}：$k=5$，多样性权重$\lambda = 0, 0.5, 0.8$。

\textbf{验证结论}：
\begin{itemize}
  \item \ding{51} $\lambda=0$时结果与传统kNN完全一致
  \item \ding{51} 随$\lambda$增大，结果的平均成对距离增大，多样性提高
  \item \ding{51} 第一个结果始终是最近邻(贪心策略起点)
\end{itemize}

\subsection{Pivot Table索引正确性验证}

\subsubsection{构建过程验证}

\textbf{验证结论}：
\begin{itemize}
  \item \ding{51} FFT策略选择的支撑点之间距离较大，分布均匀
  \item \ding{51} 距离表大小为$n \times k$
  \item \ding{51} 距离表元素满足度量空间性质(非负性、对称性)
\end{itemize}

\subsubsection{基于索引的查询结果与线性扫描结果对比}

\textbf{测试策略}：对相同的查询参数，对比线性扫描和Pivot Table索引的查询结果。

\textbf{范围查询对比}：

\begin{verbatim}
【查询参数】
  查询对象: Vector[0]
  查询半径: 0.15
  支撑点数量: 5

【一致性检验】
  结果数量: 一致 ✓
  结果对象: 一致 ✓
\end{verbatim}

\textbf{kNN查询对比}：

\begin{verbatim}
【查询参数】
  查询对象: Vector[0]
  k: 5
  支撑点数量: 5

【一致性检验】
  结果数量: 一致 ✓
  结果对象: 一致 ✓
  结果顺序: 一致 ✓
  距离值: 一致 ✓
\end{verbatim}

\textbf{验证结论}：
\begin{itemize}
  \item \ding{51} 所有测试用例中，Pivot Table索引结果与线性扫描结果完全一致
  \item \ding{51} 结果集大小、对象、顺序、距离值全部匹配
  \item \ding{51} Pivot Table索引在保证结果正确性的同时，减少了距离计算次数
  \item \ding{51} 范围查询的剪枝率通常高于kNN查询
\end{itemize}


\section{性能分析与探索}

本章通过系统的实验设计，深入分析支撑点数量、选择策略对Pivot Table查询性能的影响，并对比线性扫描与索引查询的性能差异。

\subsection{性能评估指标定义}

为了全面评估查询性能，我们定义以下关键指标：

\begin{enumerate}
  \item \textbf{查询时间(Query Time)}：执行一次查询所需的时间，单位毫秒(ms)。

  \item \textbf{平均距离计算次数(Average Distance Calculations)}：执行查询时调用距离函数的次数，是主要计算开销的来源。

  \item \textbf{剪枝数(Pruned Count)}：通过三角不等式剪枝规则排除的数据对象数量。

  \item \textbf{剪枝率(Pruning Rate)}：
  \[
  \text{剪枝率} = \frac{\text{剪枝数量}}{\text{数据集大小}} \times 100\%
  \]
  剪枝率越高，说明索引效果越好。

  \item \textbf{加速比(Speedup)}：
  \[
  \text{加速比} = \frac{\text{线性扫描时间}}{\text{索引查询时间}}
  \]
  加速比大于1说明索引带来了性能提升。

  \item \textbf{结果数量(Result Count)}：查询返回的数据对象数量，用于验证查询正确性。
\end{enumerate}

\subsection{实验设计}

\subsubsection{数据集与查询集选择}

\textbf{数据集}：
\begin{itemize}
  \item 来源：UMAD Uniform 20-d vector数据集
  \item 维度：20维均匀分布向量
  \item 距离函数：$L_2$欧几里得距离
  \item 测试规模：1000, 5000, 10000个数据点
\end{itemize}

\textbf{查询集}：
\begin{itemize}
  \item 查询对象：从数据集中随机选择
  \item 查询次数：每个配置执行10次查询，报告平均值
  \item 范围查询半径：0.05, 0.10, 0.15, 0.20
  \item kNN查询的k值：5, 10, 20, 50
\end{itemize}

\subsubsection{支撑点选择策略}

本实验对比两种支撑点选择策略：

\begin{enumerate}
  \item \textbf{RANDOM(随机选择)}：
  \begin{itemize}
    \item 优点：构建速度快，无额外距离计算
    \item 缺点：支撑点可能聚集，剪枝效果不稳定
  \end{itemize}

  \item \textbf{FFT(最远优先遍历)}：
  \begin{itemize}
    \item 优点：支撑点分布均匀，覆盖整个数据空间，剪枝效果好
    \item 缺点：构建开销较大，需要$O(nk^2)$次距离计算
  \end{itemize}
\end{enumerate}

\subsection{支撑点数量对性能的影响分析}

本实验固定数据集大小为5000，支撑点选择策略为FFT，测试不同支撑点数量(5, 10, 15, 20, 25, 30)对查询性能的影响。

\subsubsection{范围查询性能}

\textbf{实验配置}：
\begin{itemize}
  \item 数据集大小：5000个向量
  \item 支撑点数量：5, 10, 15, 20, 25, 30
  \item 查询半径：0.05, 0.10, 0.15, 0.20
  \item 查询次数：每个配置10次取平均
\end{itemize}

\textbf{实验结果}(部分数据)：

\begin{table}[H]
  \centering
  \caption{支撑点数量对范围查询性能的影响(半径=0.10)}
  \begin{tabular}{cccccc}
    \hline
    支撑点数 & 查询时间(ms) & 距离计算 & 剪枝数 & 剪枝率(\%) & 结果数 \\
    \hline
    5  & 0.254 & 10.6  & 4994.3 & 99.89 & 1.0 \\
    10 & 0.117 & 10.9  & 4999.0 & 99.98 & 1.0 \\
    15 & 0.041 & 15.9  & 4999.0 & 99.98 & 1.0 \\
    20 & 0.039 & 20.9  & 4999.0 & 99.98 & 1.0 \\
    25 & 0.044 & 25.9  & 4999.0 & 99.98 & 1.0 \\
    30 & 0.042 & 30.9  & 4999.0 & 99.98 & 1.0 \\
    \hline
  \end{tabular}
\end{table}

\textbf{关键发现}：

\begin{enumerate}
  \item \textbf{剪枝率随支撑点数量增加而提高}：从5个支撑点的99.89\%提升到10个以上的99.98\%。更多的支撑点提供了更多的剪枝机会。

  \item \textbf{查询时间先降后稳}：从5个支撑点的0.254ms降至20个支撑点的0.039ms，之后趋于稳定。这是因为剪枝效果提升的同时，剪枝判断开销也在增加。

  \item \textbf{最优支撑点数量}：对于5000个数据点的数据集，15-20个支撑点达到最佳性能平衡点。

  \item \textbf{查询半径的影响}：较小的半径(如0.05)获得更高的剪枝率(接近100\%)，因为满足查询条件的对象更少。
\end{enumerate}

\subsubsection{kNN查询性能}

\textbf{实验结果}(部分数据)：

\begin{table}[H]
  \centering
  \caption{支撑点数量对kNN查询性能的影响(k=10)}
  \begin{tabular}{ccccc}
    \hline
    支撑点数 & 查询时间(ms) & 距离计算 & 剪枝数 & 剪枝率(\%) \\
    \hline
    5  & 0.422 & 4506.1 & 498.9  & 9.98  \\
    10 & 0.482 & 4496.5 & 513.5  & 10.27 \\
    15 & 0.317 & 4470.8 & 544.2  & 10.88 \\
    20 & 0.215 & 4463.6 & 556.4  & 11.13 \\
    25 & 0.257 & 4456.9 & 568.1  & 11.36 \\
    30 & 0.206 & 4454.5 & 575.5  & 11.51 \\
    \hline
  \end{tabular}
\end{table}

\textbf{关键发现}：

\begin{enumerate}
  \item \textbf{kNN查询的剪枝率远低于范围查询}：约10\%-12\%，远低于范围查询的99\%以上。这是因为kNN查询需要精确找到k个最近邻，动态半径初期较大，剪枝效果有限。

  \item \textbf{支撑点数量增加带来的提升有限}：从5个到30个支撑点，剪枝率仅提升1.5个百分点，查询时间下降约50\%。

  \item \textbf{k值的影响}：较小的k值(如k=5)获得更高的剪枝率(约12\%)，因为动态半径缩小得更快。
\end{enumerate}

\subsection{支撑点选择策略对性能的影响分析}

本实验对比RANDOM和FFT两种支撑点选择策略的性能差异。

\textbf{实验配置}：
\begin{itemize}
  \item 数据集大小：5000个向量
  \item 支撑点数量：20
  \item 选择策略：RANDOM, FFT
  \item 查询类型：范围查询(radius=0.1)和kNN查询(k=10)
\end{itemize}

\textbf{范围查询性能对比}：

\begin{table}[H]
  \centering
  \caption{支撑点选择策略对范围查询性能的影响}
  \begin{tabular}{lcccc}
    \hline
    策略 & 构建时间(ms) & 查询时间(ms) & 剪枝率(\%) & 距离计算 \\
    \hline
    RANDOM & 5.877  & 0.043 & 99.98 & 20.9 \\
    FFT    & 54.712 & 0.044 & 99.98 & 20.9 \\
    \hline
  \end{tabular}
\end{table}

\textbf{kNN查询性能对比}：

\begin{table}[H]
  \centering
  \caption{支撑点选择策略对kNN查询性能的影响}
  \begin{tabular}{lcccc}
    \hline
    策略 & 构建时间(ms) & 查询时间(ms) & 剪枝率(\%) & 距离计算 \\
    \hline
    RANDOM & 4.150  & 0.666 & 10.38 & 4501.1 \\
    FFT    & 60.750 & 0.686 & 11.13 & 4463.6 \\
    \hline
  \end{tabular}
\end{table}

\textbf{关键发现}：

\begin{enumerate}
  \item \textbf{FFT构建时间远高于RANDOM}：FFT需要54.712ms，RANDOM仅需5.877ms(范围查询)。FFT的$O(nk^2)$复杂度导致构建开销大。

  \item \textbf{查询性能差异不明显}：在本数据集上，两种策略的查询时间和剪枝率差异很小。这可能是因为20维均匀分布数据较为规则，随机选择的支撑点也能获得较好的覆盖。

  \item \textbf{策略选择建议}：
  \begin{itemize}
    \item 对于一次性查询：RANDOM策略更合适，构建快速
    \item 对于多次查询：FFT策略的构建开销可以分摊，且在聚类数据上效果更稳定
  \end{itemize}
\end{enumerate}

\subsection{查询性能对比：线性扫描 vs. Pivot Table索引}

本实验对比线性扫描和Pivot Table索引在不同数据集规模下的性能表现。

\subsubsection{范围查询性能对比}

\textbf{实验配置}：
\begin{itemize}
  \item 数据集大小：1000, 5000, 10000
  \item 支撑点数量：20(FFT策略)
  \item 查询半径：0.05, 0.10, 0.15, 0.20
\end{itemize}

\textbf{实验结果}：

\begin{table}[H]
  \centering
  \caption{范围查询：线性扫描 vs Pivot Table(半径=0.10)}
  \begin{tabular}{ccccc}
    \hline
    数据集大小 & 线性扫描(ms) & 索引查询(ms) & 加速比 & 剪枝率(\%) \\
    \hline
    1000  & 0.132 & 0.010 & 13.83x & 99.90 \\
    5000  & 0.313 & 0.056 & 5.57x  & 99.98 \\
    10000 & 1.480 & 0.151 & 9.82x  & 99.99 \\
    \hline
  \end{tabular}
\end{table}

\textbf{关键发现}：

\begin{enumerate}
  \item \textbf{Pivot Table显著加速范围查询}：加速比在5.57x-13.83x之间，数据集越大，加速效果越明显。

  \item \textbf{剪枝率极高}：范围查询的剪枝率达到99\%以上，说明三角不等式剪枝非常有效。

  \item \textbf{查询时间随数据集大小线性增长}：线性扫描的时间复杂度为$O(n)$，而Pivot Table通过剪枝将实际计算降至$O(k + \alpha n)$，其中$\alpha$很小。
\end{enumerate}

\subsubsection{kNN查询性能对比}

\textbf{实验结果}：

\begin{table}[H]
  \centering
  \caption{kNN查询：线性扫描 vs Pivot Table(k=10)}
  \begin{tabular}{ccccc}
    \hline
    数据集大小 & 线性扫描(ms) & 索引查询(ms) & 加速比 & 剪枝率(\%) \\
    \hline
    1000  & 0.155 & 0.071 & 2.18x & 11.28 \\
    5000  & 0.313 & 0.204 & 1.53x & 11.13 \\
    10000 & 2.408 & 1.738 & 1.39x & 12.77 \\
    \hline
  \end{tabular}
\end{table}

\textbf{关键发现}：

\begin{enumerate}
  \item \textbf{kNN查询加速有限}：加速比仅1.39x-2.18x，远低于范围查询。这是因为kNN查询的剪枝率较低(约11\%-13\%)，大部分对象仍需计算实际距离。

  \item \textbf{动态半径策略的局限}：kNN查询的动态半径初期较大，剪枝效果不如固定半径的范围查询。

  \item \textbf{优化空间}：可以考虑预先估计k近邻的距离范围，或采用增量式查询策略来提升剪枝效果。
\end{enumerate}

\subsection{性能分析总结}

基于以上实验，我们得出以下结论：

\begin{enumerate}
  \item \textbf{支撑点数量}：15-20个支撑点是5000-10000规模数据集的最佳平衡点。过少剪枝不足，过多判断开销增大。

  \item \textbf{支撑点选择策略}：FFT策略在聚类数据上更稳定，但均匀分布数据上与RANDOM差异不大。应根据数据特征和查询频率选择。

  \item \textbf{范围查询优化}：Pivot Table对范围查询的加速效果显著(5-13倍)，剪枝率达99\%以上，是理想的索引方法。

  \item \textbf{kNN查询优化}：Pivot Table对kNN查询的加速有限(1.4-2倍)，剪枝率仅约11\%，需要更先进的索引结构(如VP-tree, M-tree)来进一步优化。

  \item \textbf{实际应用建议}：
  \begin{itemize}
    \item 对于范围查询为主的应用，强烈推荐使用Pivot Table索引
    \item 对于kNN查询为主的应用，可以考虑结合多种索引策略
    \item 数据规模越大，索引带来的性能提升越明显
  \end{itemize}
\end{enumerate}


\section{总结与展望}

\subsection{工作总结}

本实验报告在Assignment 1构建的度量空间数据管理基础框架之上，成功实现了相似性查询与索引功能，取得了以下成果：

\subsubsection{核心功能实现}

\begin{enumerate}
  \item \textbf{线性扫描查询}：
  \begin{itemize}
    \item 实现了范围查询(Range Query)、k近邻查询(kNN Query)和多样化k近邻查询(dkNN Query)三种基本查询算法
    \item 算法设计通用，支持所有满足度量空间性质的数据类型
    \item 作为索引查询的正确性验证基准
  \end{itemize}

  \item \textbf{Pivot Table索引}：
  \begin{itemize}
    \item 实现了基于三角不等式的剪枝优化索引结构
    \item 支持RANDOM、FFT、CENTER、BORDER四种支撑点选择策略
    \item 实现了基于索引的范围查询和kNN查询算法
    \item 在范围查询上取得了显著的性能提升(5-13倍加速)
  \end{itemize}

  \item \textbf{系统架构}：
  \begin{itemize}
    \item 保持了Assignment 1的分层设计，查询和索引模块与核心抽象无缝集成
    \item 遵循"依赖倒置"和"开闭原则"，易于扩展新的查询类型和索引结构
    \item 代码结构清晰，注释完善，便于理解和维护
  \end{itemize}
\end{enumerate}

\subsubsection{正确性验证}

\begin{itemize}
  \item 设计了易于验证的小规模测试用例，输出详细的计算过程
  \item 验证了Pivot Table索引查询结果与线性扫描完全一致
  \item 通过JUnit测试框架实现了自动化测试，确保系统稳定性
  \item 验证了度量空间三大性质(非负性、对称性、三角不等性)在实现中的正确应用
\end{itemize}

\subsubsection{性能分析成果}

\begin{itemize}
  \item 系统分析了支撑点数量对查询性能的影响，发现15-20个支撑点是最佳平衡点
  \item 对比了RANDOM和FFT两种支撑点选择策略，揭示了它们的适用场景
  \item 量化了Pivot Table索引的加速效果：范围查询5-13倍，kNN查询1.4-2倍
  \item 揭示了范围查询和kNN查询在剪枝效果上的显著差异(99\% vs 11\%)
\end{itemize}

\subsubsection{理论理解深化}

通过本次实验，我们深入理解了以下核心概念：

\begin{itemize}
  \item \textbf{度量空间通用性}：相同的算法可以处理向量、蛋白质序列等多种数据类型，只需定义满足度量空间性质的距离函数
  \item \textbf{三角不等式的威力}：看似简单的数学性质，在索引优化中发挥了关键作用，将距离计算从$O(n)$降至$O(k + \alpha n)$
  \item \textbf{剪枝策略的局限性}：Pivot Table对范围查询效果显著，但对kNN查询效果有限，不同查询类型需要不同的优化策略
  \item \textbf{通用与专用的权衡}：通用的度量空间索引牺牲了部分性能，但换来了代码复用和系统的可扩展性
\end{itemize}

\subsection{系统不足与改进方向}

尽管本系统实现了预期目标，但仍存在一些不足之处，可在未来工作中改进：

\subsubsection{性能优化}

\begin{enumerate}
  \item \textbf{kNN查询优化}：
  \begin{itemize}
    \item 当前Pivot Table对kNN查询的加速效果有限(仅1.4-2倍)
    \item 可以引入更先进的索引结构，如VP-tree(Vantage Point Tree)、M-tree或MVP-tree
    \item 可以采用预估k近邻距离范围的策略，缩小初始动态半径
  \end{itemize}

  \item \textbf{支撑点选择优化}：
  \begin{itemize}
    \item 当前FFT策略的构建开销较大($O(nk^2)$)
    \item 可以采用抽样式FFT，在样本上选择支撑点，降低复杂度
    \item 可以研究自适应支撑点选择算法，根据数据分布动态调整
  \end{itemize}

  \item \textbf{并行化}：
  \begin{itemize}
    \item 当前实现是单线程的，未充分利用多核处理器
    \item Pivot Table的距离表构建天然支持并行化
    \item 范围查询的线性扫描部分也可以并行化
  \end{itemize}
\end{enumerate}

\subsubsection{功能扩展}

\begin{enumerate}
  \item \textbf{更多查询类型}：
  \begin{itemize}
    \item 实现反向k近邻查询(Reverse kNN)
    \item 实现范围内的多样化查询
    \item 实现Top-k聚合查询
  \end{itemize}

  \item \textbf{更多索引结构}：
  \begin{itemize}
    \item 实现VP-tree、M-tree等树状索引结构
    \item 实现LAESA(Linear Approximating and Eliminating Search Algorithm)
    \item 对比不同索引结构在各种数据和查询场景下的性能
  \end{itemize}

  \item \textbf{动态数据支持}：
  \begin{itemize}
    \item 当前索引是静态的，不支持数据的增删改
    \item 可以设计增量式索引维护算法
    \item 研究批量更新策略，平衡更新开销和查询性能
  \end{itemize}
\end{enumerate}

\subsubsection{实验深化}

\begin{enumerate}
  \item \textbf{更多数据集}：
  \begin{itemize}
    \item 当前仅测试了均匀分布的向量数据
    \item 应测试聚类数据、真实地理数据(Texas, Hawaii)和蛋白质序列数据
    \item 分析不同数据分布对索引性能的影响
  \end{itemize}

  \item \textbf{更大规模}：
  \begin{itemize}
    \item 当前最大测试规模为10000个数据点
    \item 应测试100K、1M规模的数据集
    \item 分析索引的可扩展性
  \end{itemize}

  \item \textbf{理论分析}：
  \begin{itemize}
    \item 当前主要是实验性能分析
    \item 可以进行理论复杂度分析和期望性能推导
    \item 研究剪枝率的上界和下界
  \end{itemize}
\end{enumerate}

\subsubsection{工程实践}

\begin{enumerate}
  \item \textbf{性能优化}：
  \begin{itemize}
    \item 采用更高效的数据结构(如Java NIO的ByteBuffer)
    \item 优化距离计算的实现(如SIMD向量化)
    \item 引入缓存机制，避免重复计算
  \end{itemize}

  \item \textbf{可视化}：
  \begin{itemize}
    \item 开发可视化工具，直观展示剪枝过程
    \item 绘制性能曲线图，辅助参数调优
    \item 可视化支撑点分布和查询过程
  \end{itemize}

  \item \textbf{易用性}：
  \begin{itemize}
    \item 提供命令行工具和图形界面
    \item 编写详细的API文档和使用示例
    \item 支持配置文件，简化系统配置
  \end{itemize}
\end{enumerate}

\subsection{展望}

度量空间数据管理作为一种通用的数据处理范式，在大数据时代具有重要的理论价值和应用前景。通过本次实验，我们不仅实现了基本的相似性查询和索引功能，更重要的是理解了"求同存异"的通用性思想和三角不等式的数学之美。

未来，随着人工智能和大数据应用的发展，度量空间技术有望在图像检索、推荐系统、生物信息学等领域发挥更大作用。我们将继续深入研究度量空间索引的理论和实践，为构建高效、通用的大数据管理系统贡献力量。文章涉及的所有代码均已上传至GitHub仓库：\url{https://github.com/sylvanding/BigDataGenhierarchy_Jixiang_20251116}。

\printbibliography[heading=bibliography,title=参考文献]

\end{document}
